{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import functools\n",
    "\n",
    "from stljax.formula import Predicate, Eventually, Always, DifferentiableAlways\n",
    "from stljax.viz import make_stl_graph\n",
    "from stljax.utils import anneal\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define single integrator dynamics\n",
    "@jax.jit\n",
    "def dynamics_discrete_step(state, control, dt=0.1):\n",
    "    '''Single integrator dynamics'''\n",
    "    return state + control * dt\n",
    "\n",
    "# roll out states for a sequence of controls\n",
    "@jax.jit\n",
    "def simulate_dynamics(controls, state0, dt):\n",
    "    '''Function to roll out initial state and controls'''\n",
    "    def scan_fn(state, control):\n",
    "        new_state = dynamics_discrete_step(state, control, dt)\n",
    "        return new_state, new_state[0]\n",
    "    return jnp.concatenate([state0, jax.lax.scan(scan_fn, state0, controls)[1]], axis=0)\n",
    "\n",
    "# predicate function - distance from a point\n",
    "@jax.jit\n",
    "def compute_distance_to_point(states, point):\n",
    "    return jnp.linalg.norm(states[...,:2] - point, axis=-1, keepdims=True)\n",
    "\n",
    "# predicate function - distance from origin\n",
    "@jax.jit\n",
    "def compute_distance_to_origin(states):\n",
    "    return compute_distance_to_point(states, jnp.zeros(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining STL formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment parameters\n",
    "# target region can be treated as an obstacle or a region to visit\n",
    "target_center = jnp.array([[0, 2]]) # target location\n",
    "reach_radius = 0.1 # radius considered to have reached goal \n",
    "target_radius = 0.5 # radius of the target + agent circular footprint\n",
    "\n",
    "\n",
    "distance_to_origin = Predicate(\"distance to origin\", compute_distance_to_origin)\n",
    "distance_to_target = Predicate(\"distance to target\", functools.partial(compute_distance_to_point, point=target_center))\n",
    "\n",
    "reach = Eventually(distance_to_origin < reach_radius) # eventually reach the goal\n",
    "avoid = Always(distance_to_target > target_radius) # always avoid target\n",
    "# stay = Eventually(Always(distance_to_target < 0.5, interval=[0, 7]), interval=[0,20])   # if you don't want to have differentiable time intervals\n",
    "stay = DifferentiableAlways(distance_to_target < 0.5) # stay inside target region\n",
    "\n",
    "formula = reach & stay\n",
    "# formula = Until(distance_to_target > 0.5, Always(distance_to_origin < 0.5), interval=[40,45])\n",
    "\n",
    "make_stl_graph(formula)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponenial_penalty(x):\n",
    "    return jnp.exp(x)\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=(\"approx_method\"))\n",
    "def loss(controls, t_start, t_end, scale, state0, umax, dt, coeffs=jnp.array([1., 0.1, 5., 0.]), approx_method=\"true\", temperature=None):\n",
    "    # see paper for more details on loss function\n",
    "    # generate trajectory from control sequence and reverse along time dimension\n",
    "    traj = simulate_dynamics(controls, state0, dt)\n",
    "    # loss functions\n",
    "    \n",
    "    # penalize for negative robustness, no penality for positive robustness\n",
    "    loss_robustness = jax.nn.relu(-formula.robustness(traj, t_start=t_start, t_end=t_end, scale=scale, approx_method=approx_method, temperature=temperature))\n",
    "    \n",
    "    # loss to encourage controls to be smooth. Total variation + mean squared\n",
    "    total_variation_weight = 0.1\n",
    "    loss_control_smoothness = total_variation_weight * jnp.abs(jnp.diff(controls, axis=1)).sum(-1).mean()  + (controls**2).sum(-1).mean() \n",
    "    \n",
    "    # penalize for control limit violation\n",
    "    loss_control_limits = jax.nn.relu(jnp.linalg.norm(controls, axis=-1) - umax).mean() \n",
    "    \n",
    "    # encourage time duration in target region to be as long as possible, encouraging at least min_interval.\n",
    "    min_interval = 0.2\n",
    "    interval_difference = min_interval - (t_end - t_start)  # negative is good\n",
    "    \n",
    "    # cost vector\n",
    "    cost_array = jnp.array([\n",
    "        loss_robustness,\n",
    "        loss_control_smoothness,\n",
    "        loss_control_limits,\n",
    "        exponenial_penalty(2 * interval_difference)\n",
    "    ])\n",
    "    \n",
    "    # multiply with weighting coefficients\n",
    "    return jnp.dot(coeffs, cost_array)\n",
    "    \n",
    "grad_jit = jax.jit(jax.grad(loss, [0,1,2]), static_argnames=\"approx_method\") # get gradient of loss with respect to controls, t_start, t_end\n",
    "\n",
    "\n",
    "# compute true robustness of a trajectory\n",
    "@jax.jit\n",
    "def true_robustness(controls, t_start, t_end, scale, state0, dt):\n",
    "    traj = simulate_dynamics(controls, state0, dt)\n",
    "    return formula.robustness(traj, t_start=t_start, t_end=t_end, scale=scale).mean()\n",
    "\n",
    "@jax.jit\n",
    "def schedule(i, i_max, start, end):\n",
    "    j = (i / i_max)\n",
    "    temp = anneal(j)\n",
    "    return temp * (end - start) + start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up parameters to begin the gradient descent routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "T = 51  # time horizon\n",
    "dt = 0.1 # time step size\n",
    "ts = jnp.array([t * dt for t in range(T)]) # time step array\n",
    "umax = 2.  # max control limit\n",
    "\n",
    "controls = jnp.array(np.random.randn(T,2))  # initial random control sequence\n",
    "state0 = jnp.ones(2).reshape([1,2]) * 3. # initial state\n",
    "states_ = [simulate_dynamics(controls, state0, dt)]  # list to collect all the state trajectories at each gradient descent step\n",
    "\n",
    "# initial values for time interval (before passing through softmax)\n",
    "t_start = -1.8\n",
    "t_end = 1.5\n",
    "\n",
    "lr = 1E-2 # learning rate\n",
    "approx_method = \"logsumexp\"\n",
    "n_steps = 10000   # number of gradient steps\n",
    "\n",
    "# start and end values for annealing temperature and scale\n",
    "start_temp = 1\n",
    "end_temp = 100\n",
    "\n",
    "start_scale = 10\n",
    "end_scale = 100\n",
    "\n",
    "coeffs = jnp.array([1.1, 0.5, 2., 0.05]) # coefficients for loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the functions to test them out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 0.1\n",
    "loss(controls, t_start, t_end, scale, state0, umax, dt)\n",
    "loss(controls, t_start, t_end, scale, state0, umax, dt, approx_method=\"softmax\", temperature=5)\n",
    "true_robustness(controls, t_start, t_end, scale, state0, dt)\n",
    "grad_jit(controls, t_start, t_end, scale, state0, umax, dt, coeffs, approx_method, 0.2);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run optimization loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(n_steps):\n",
    "    \n",
    "    # get annealed temperature and scale\n",
    "    temperature = schedule(i, n_steps, start_temp, end_temp)\n",
    "    scale = schedule(i, n_steps, start_scale, end_scale)\n",
    "    \n",
    "    # get t_start and t_end in [0, 1] range\n",
    "    t_start_ = jax.nn.sigmoid(t_start)\n",
    "    t_end_ = jax.nn.sigmoid(t_end)\n",
    "    \n",
    "    # compute gradient of loss with respect to controls, t_start, t_end\n",
    "    g1, g2, g3 = grad_jit(controls, t_start_, t_end_, scale, state0, umax, dt, coeffs, approx_method, temperature)  # take gradient\n",
    "    \n",
    "    # stop loop if gradient is small or NaN\n",
    "    if ((jnp.linalg.norm(g1)/ T / 2) < 5E-6) or (jnp.isnan(g1).sum() > 0):\n",
    "        break\n",
    "\n",
    "    # update controls and time interval    \n",
    "    controls -= g1 * lr\n",
    "    # account for sigmoid transformation of t_start and t_end\n",
    "    t_start -= g2 * lr * t_start_ * (1 - t_start_) \n",
    "    t_end -= g3 * lr * t_end_ * (1 - t_end_)\n",
    "    \n",
    "    # collect state trajectory for the current controls\n",
    "    states_.append(simulate_dynamics(controls, state0, dt))\n",
    "    \n",
    "    # print out every 50th step\n",
    "    if (i % 50) == 0:\n",
    "        t_start_ = jax.nn.sigmoid(t_start)\n",
    "        t_end_ = jax.nn.sigmoid(t_end)\n",
    "        print(\"%3i -- true robustness: %.2f   smoothness: %.2f    control limits: %.2f    interval: %.2f t_start: %.2f    t_end: %.2f\"%(i, true_robustness(controls, t_start_, t_end_, 1000., state0, dt), loss(controls, t_start_, t_end_, 1000., state0, umax, dt, coeffs=jnp.array([0., 1., 0., 0.])), loss(controls, t_start_, t_end_, 1000., state0, umax, dt, coeffs=jnp.array([0., 0., 1., 0.])), loss(controls, t_start_, t_end_, 1000., state0, umax, dt, coeffs=jnp.array([0., 0., 0., 1.])), t_start_, t_end_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualize final solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(15,4)) \n",
    "\n",
    "ax = axs[0]\n",
    "circle1 = plt.Circle((0, 0), 0.2, color='C2', alpha=0.4)\n",
    "circle2 = plt.Circle(target_center[0], 0.5, color='C1', alpha=0.4)\n",
    "\n",
    "ax.add_patch(circle1)\n",
    "ax.add_patch(circle2)\n",
    "\n",
    "N = 250\n",
    "[ax.plot(*s.T, color=\"k\", alpha=0.2) for s in states_[::N]]\n",
    "[ax.plot(*s.T, color=\"blue\", label=\"Initial traj\") for s in states_[:1]]\n",
    "[ax.plot(*s.T, '.-', color=\"r\", markersize=10, label=\"Final traj\") for s in states_[-1:]]\n",
    "\n",
    "ax.scatter(states_[-1][0,:1], states_[-1][0,1:], marker=\"^\", c='yellow', edgecolor=\"k\", s=100, label=\"start\", zorder=4)\n",
    "ax.scatter(states_[-1][-1,:1], states_[-1][-1,1:], marker=\"*\", c='yellow', edgecolor=\"k\", s=200, label=\"end\", zorder=4)\n",
    "\n",
    "ax.set_xlabel(\"x position\")\n",
    "ax.set_ylabel(\"y position\")\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.axis(\"equal\")\n",
    "ax.set_title(\"Trajectory\")\n",
    "\n",
    "# plot x, y\n",
    "ax = axs[1]\n",
    "# ax.plot(ts, states_[-1][:-1,:1], label=\"x\")\n",
    "# ax.plot(ts, states_[-1][:-1,1:], label=\"y\")\n",
    "ax.plot(ts, distance_to_origin.predicate_function(states_[-1][1:]).squeeze(), label=\"distance to origin\")\n",
    "ax.hlines(reach_radius, ts[0], ts[-1], color=\"C0\", linestyle=\"--\", label=\"reach radius\")\n",
    "ax.plot(ts, distance_to_target.predicate_function(states_[-1][1:]).squeeze(), label=\"distance to target\")\n",
    "ax.hlines(target_radius, ts[0], ts[-1], color=\"C1\", linestyle=\"--\", label=\"target radius\")\n",
    "ax.grid()\n",
    "ax.axis(\"equal\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Distance\")\n",
    "ax.set_title(\"Distance to regions over time\")\n",
    "\n",
    "# plot control signal\n",
    "ax = axs[2]\n",
    "ax.plot(ts, controls[:,:1], label=\"x control\")\n",
    "ax.plot(ts, controls[:,1:], label=\"y control\")\n",
    "ax.plot(ts, jnp.linalg.norm(controls, axis=-1).squeeze(), label=\"control norm\")\n",
    "ax.grid()\n",
    "ax.axis(\"equal\")\n",
    "ax.legend(ncols=3)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Controls\")\n",
    "ax.set_title(\"Control sequence\")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 14\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "def visualize_solution(ax, i):\n",
    "\n",
    "    circle1 = plt.Circle((0, 0), 0.2, color='C2', alpha=0.7)\n",
    "    circle2 = plt.Circle(target_center[0], 0.5, color='C1', alpha=0.7)\n",
    "\n",
    "\n",
    "    # [ax.plot(*s.T, color=\"blue\", label=\"Initial traj\", alpha=0.6) for s in states_[:1]]\n",
    "    # [ax.plot(*s.T, '.-', color=\"r\", label=\"Final traj\", zorder=10, linewidth=2, markersize=8) for s in states_[-1:]]\n",
    "    ax.scatter(states_[i][0,:1], states_[i][0,1:], zorder=10, label=\"start\", color=\"yellow\", edgecolor=\"black\", marker=\"^\", s=100)\n",
    "    ax.scatter(states_[i][-1,:1], states_[i][-1,1:], zorder=10, label=\"end\", color=\"yellow\", edgecolor=\"black\", marker=\"*\", s=200)\n",
    "    ax.plot(*states_[i].T, 'o-', color=\"k\", alpha=0.4, zorder=9, linewidth=2)\n",
    "\n",
    "    ax.add_patch(circle1)\n",
    "    ax.add_patch(circle2)\n",
    "\n",
    "    ax.annotate(\"Goal\", (-0.4, -0.4), fontsize=fontsize-2)\n",
    "    ax.annotate(\"Target\", (-0.4, 2.7), fontsize=fontsize-2)\n",
    "\n",
    "    ax.set_xlabel(\"$x$ position [m]\", fontsize=fontsize, labelpad=-2)\n",
    "    ax.set_ylabel(\"$y$ position [m]\", fontsize=fontsize)\n",
    "    ax.set_title(\"Robustness $\\\\rho$ = %.2f\"%formula.robustness(states_[i], t_start=jax.nn.sigmoid(t_start), t_end=jax.nn.sigmoid(t_end), scale=1000.), fontsize=fontsize)\n",
    "    ax.grid(zorder=-6, alpha=0.5)\n",
    "    ax.legend([\"Start\", \"End\", \"Solution $i=%i$\"%i], ncol=1, fontsize=fontsize-3)\n",
    "    ax.axis(\"equal\")\n",
    "    ax.set_xlim(-1.0, 3.5)\n",
    "    ax.set_ylim(-1.0, 3.5)\n",
    "    plt.tight_layout()\n",
    "\n",
    "visualize_solution(ax, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "N = 250  # show intermediate solutions at every N iterations\n",
    "\n",
    "def animate(idx):\n",
    "    ax.clear()\n",
    "    visualize_solution(ax, idx)\n",
    "\n",
    "frames = range(0, len(states_)-1, N)\n",
    "ani = animation.FuncAnimation(fig, animate, frames=frames, interval=100, repeat=False)\n",
    "\n",
    "plt.close(fig)  # Prevent duplicate static plot in notebook output\n",
    "HTML(ani.to_jshtml()) # Display the animation in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a static plot of the final solution, from paper\n",
    "\n",
    "fontsize = 14\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "circle1 = plt.Circle((0, 0), 0.2, color='C2', alpha=0.7)\n",
    "circle2 = plt.Circle(target_center[0], 0.5, color='C1', alpha=0.7)\n",
    "\n",
    "N = 250 # show intermediate solutions at everge N iterations\n",
    "\n",
    "[ax.plot(*s.T, color=\"blue\", label=\"Initial traj\", alpha=0.6) for s in states_[:1]]\n",
    "[ax.plot(*s.T, '.-', color=\"r\", label=\"Final traj\", zorder=10, linewidth=2, markersize=8) for s in states_[-1:]]\n",
    "ax.scatter(states_[-1][0,:1], states_[-1][0,1:], zorder=10, label=\"start\", color=\"yellow\", edgecolor=\"black\", marker=\"^\", s=100)\n",
    "ax.scatter(states_[-1][-1,:1], states_[-1][-1,1:], zorder=10, label=\"end\", color=\"yellow\", edgecolor=\"black\", marker=\"*\", s=200)\n",
    "[ax.plot(*s.T, color=\"k\", alpha=0.2, label=\"Iterations\", zorder=0) for s in states_[::N]]\n",
    "\n",
    "ax.add_patch(circle1)\n",
    "ax.add_patch(circle2)\n",
    "\n",
    "ax.annotate(\"Goal\", (-0.4, -0.4), fontsize=fontsize-2)\n",
    "ax.annotate(\"Target\", (-0.4, 2.7), fontsize=fontsize-2)\n",
    "\n",
    "ax.set_xlabel(\"$x$ position [m]\", fontsize=fontsize, labelpad=-2)\n",
    "ax.set_ylabel(\"$y$ position [m]\", fontsize=fontsize)\n",
    "ax.set_title(\"Robustness $\\\\rho$ = %.2f\"%formula.robustness(states_[-1], t_start=jax.nn.sigmoid(t_start), t_end=jax.nn.sigmoid(t_end), scale=1000.), fontsize=fontsize)\n",
    "ax.grid(zorder=-6, alpha=0.5)\n",
    "ax.legend([\"Initial guess\", \"Final trajectory\", \"Start\", \"End\"], ncol=1, fontsize=fontsize-3)\n",
    "ax.axis(\"equal\")\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
